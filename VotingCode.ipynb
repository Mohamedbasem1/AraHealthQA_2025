{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def weighted_ensemble_predictions(file1_path, file2_path, file3_path, file4_path):\n",
    "    \"\"\"\n",
    "    Create weighted ensemble from 4 CSV files based on their performance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV files\n",
    "    df1 = pd.read_csv(file1_path)\n",
    "    df2 = pd.read_csv(file2_path)\n",
    "    df3 = pd.read_csv(file3_path)\n",
    "    df4 = pd.read_csv(file4_path)\n",
    "    \n",
    "    # Define weights based on accuracy scores\n",
    "    weights = {\n",
    "        'model1': 0.73,  # 73% accuracy\n",
    "        'model2': 0.73,  # 73% accuracy\n",
    "        'model3': 0.76,  # 76% accuracy\n",
    "        'model4': 0.75   # 75% accuracy (adjust as needed)\n",
    "    }\n",
    "    \n",
    "    # Normalize weights to sum to 1\n",
    "    total_weight = sum(weights.values())\n",
    "    normalized_weights = {k: v/total_weight for k, v in weights.items()}\n",
    "    \n",
    "    # Assuming predictions are in a column named 'prediction' \n",
    "    # Adjust column name as needed\n",
    "    pred_col = 'prediction' if 'prediction' in df1.columns else df1.columns[0]\n",
    "    \n",
    "    predictions1 = df1[pred_col].values\n",
    "    predictions2 = df2[pred_col].values  \n",
    "    predictions3 = df3[pred_col].values\n",
    "    predictions4 = df4[pred_col].values\n",
    "    \n",
    "    # Ensure all arrays have same length\n",
    "    min_len = min(len(predictions1), len(predictions2), len(predictions3), len(predictions4))\n",
    "    predictions1 = predictions1[:min_len]\n",
    "    predictions2 = predictions2[:min_len]\n",
    "    predictions3 = predictions3[:min_len]\n",
    "    predictions4 = predictions4[:min_len]\n",
    "    \n",
    "    ensemble_predictions = []\n",
    "    \n",
    "    # Weighted voting for each sample\n",
    "    for i in range(min_len):\n",
    "        # Create weighted votes dictionary\n",
    "        votes = {}\n",
    "        \n",
    "        # Add weighted votes for each model\n",
    "        for pred, weight in [(predictions1[i], normalized_weights['model1']),\n",
    "                           (predictions2[i], normalized_weights['model2']),\n",
    "                           (predictions3[i], normalized_weights['model3']),\n",
    "                           (predictions4[i], normalized_weights['model4'])]:\n",
    "            if pred in votes:\n",
    "                votes[pred] += weight\n",
    "            else:\n",
    "                votes[pred] = weight\n",
    "        \n",
    "        # Select prediction with highest weighted vote\n",
    "        ensemble_pred = max(votes.items(), key=lambda x: x[1])[0]\n",
    "        ensemble_predictions.append(ensemble_pred)\n",
    "    \n",
    "    return ensemble_predictions, normalized_weights\n",
    "\n",
    "\n",
    "def simple_majority_voting(file1_path, file2_path, file3_path, file4_path):\n",
    "    \"\"\"\n",
    "    Alternative: Simple majority voting (unweighted) for 4 models\n",
    "    \"\"\"\n",
    "    df1 = pd.read_csv(file1_path)\n",
    "    df2 = pd.read_csv(file2_path)\n",
    "    df3 = pd.read_csv(file3_path)\n",
    "    df4 = pd.read_csv(file4_path)\n",
    "    \n",
    "    pred_col = 'prediction' if 'prediction' in df1.columns else df1.columns[0]\n",
    "    \n",
    "    predictions1 = df1[pred_col].values\n",
    "    predictions2 = df2[pred_col].values  \n",
    "    predictions3 = df3[pred_col].values\n",
    "    predictions4 = df4[pred_col].values\n",
    "    \n",
    "    min_len = min(len(predictions1), len(predictions2), len(predictions3), len(predictions4))\n",
    "    ensemble_predictions = []\n",
    "    \n",
    "    for i in range(min_len):\n",
    "        # Count votes for each class\n",
    "        votes = [predictions1[i], predictions2[i], predictions3[i], predictions4[i]]\n",
    "        vote_counts = Counter(votes)\n",
    "        \n",
    "        # Get majority vote (or first in case of tie)\n",
    "        majority_vote = vote_counts.most_common(1)[0][0]\n",
    "        ensemble_predictions.append(majority_vote)\n",
    "    \n",
    "    return ensemble_predictions\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual file paths\n",
    "    file1 = \"73_predictions_subtask1_test.csv\"\n",
    "    file2 = \"73_2_predictions_subtask1_test.csv\" \n",
    "    file3 = \"76_predictions_subtask1_test.csv\"\n",
    "    file4 = \"75_predictions_subtask1_test.csv\"  # Add your fourth model file\n",
    "    \n",
    "    # Method 1: Weighted ensemble (recommended)\n",
    "    ensemble_preds, weights = weighted_ensemble_predictions(file1, file2, file3, file4)\n",
    "    \n",
    "    print(\"Normalized weights used:\")\n",
    "    for model, weight in weights.items():\n",
    "        print(f\"{model}: {weight:.3f}\")\n",
    "    \n",
    "    print(f\"\\nFirst 10 ensemble predictions: {ensemble_preds[:10]}\")\n",
    "    \n",
    "    # Create DataFrame from ensemble predictions\n",
    "    ensemble_df = pd.DataFrame({'prediction': ensemble_preds})\n",
    "    # Save ensemble predictions to CSV (keeping all records)\n",
    "    ensemble_df.to_csv('ensemble_predictions.csv', index=False, encoding='utf-8')\n",
    "    \n",
    "    # Method 2: Simple majority voting\n",
    "    majority_preds = simple_majority_voting(file1, file2, file3, file4)\n",
    "    \n",
    "    # Compare both methods (using all records)\n",
    "    agreement = sum(1 for i in range(len(ensemble_preds)) \n",
    "                   if ensemble_preds[i] == majority_preds[i])\n",
    "    print(f\"\\nAgreement between weighted and majority voting: {agreement/len(ensemble_preds):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
